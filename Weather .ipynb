{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.context.SparkContext at 0x633ab00>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the average amount of people using the MTA during different weather conditions during 2011-2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Rain', 159L),\n",
       " ('Rain , Snow', 159),\n",
       " ('Fog , Snow', 126),\n",
       " ('Fog , Rain', 156),\n",
       " ('Clear Skies', 157L),\n",
       " ('Snow', 151),\n",
       " ('Fog', 171),\n",
       " ('Fog , Rain , Snow', 146),\n",
       " ('Thunderstorm', 75)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mapper1(index,data):\n",
    "    # skip header row\n",
    "    if index==0:\n",
    "        data.next()\n",
    "    import csv\n",
    "    reader = csv.reader(data)\n",
    "    for row in reader:\n",
    "        event = row[4]\n",
    "        numPeople = row[5].split('.')[0]\n",
    "        if event == 'Normal':\n",
    "            yield ('Clear Skies', int(numPeople))\n",
    "        else:\n",
    "            yield (event, int(numPeople))\n",
    "        \n",
    "def mapper2(index,data):\n",
    "    # skip header row\n",
    "    if index==0:\n",
    "        data.next()\n",
    "    import csv\n",
    "    reader = csv.reader(data)\n",
    "    for row in reader:\n",
    "        date = row[1]\n",
    "        event = row[4]\n",
    "        if event == 'Normal':\n",
    "            yield ((date, 'Clear Skies'), 1)\n",
    "        else:\n",
    "            yield ((date, event), 1)\n",
    "\n",
    "mtaData = sc.textFile('dataset/clean-mta-data/clean-mta-data.csv',use_unicode=False).cache()\n",
    "\n",
    "# sum up all the entry by weather\n",
    "# returns (event, total_people)\n",
    "rdd1 = mtaData.mapPartitionsWithIndex(mapper1) \\\n",
    "                .reduceByKey(lambda x,y: x+y)\n",
    "\n",
    "# count how many days that have certain weather\n",
    "# d = date; e = event; c = count;\n",
    "# returns (event, count)\n",
    "rdd2 = mtaData.mapPartitionsWithIndex(mapper2) \\\n",
    "                .reduceByKey(lambda x,y: x+y) \\\n",
    "                .map(lambda ((d, e), c): (e, c)) \\\n",
    "                .reduceByKey(lambda x,y: x+y)\n",
    "\n",
    "# get average Entry in day for weather\n",
    "# d = date; e = event; c = count; s = summation\n",
    "# returns (event, average_peple_per_weather)\n",
    "rdd3 = rdd1.join(rdd2) \\\n",
    "           .map(lambda (e, (s, c)): (e, s/c)) \\\n",
    "           .collect()\n",
    "rdd3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the average amount of people using the MTA by day of the week and weather condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((6, 'Rain'), 86),\n",
       " ((6, 'Clear Skies'), 88),\n",
       " ((1, 'Fog , Snow'), 151),\n",
       " ((0, 'Fog , Snow'), 118),\n",
       " ((5, 'Fog , Rain , Snow'), 98),\n",
       " ((3, 'Rain , Snow'), 181),\n",
       " ((3, 'Fog , Rain , Snow'), 155),\n",
       " ((3, 'Clear Skies'), 185),\n",
       " ((5, 'Snow'), 107),\n",
       " ((2, 'Fog'), 194),\n",
       " ((3, 'Fog , Snow'), 136),\n",
       " ((4, 'Rain , Snow'), 184),\n",
       " ((0, 'Snow'), 173),\n",
       " ((2, 'Clear Skies'), 186),\n",
       " ((4, 'Snow'), 178),\n",
       " ((0, 'Clear Skies'), 173),\n",
       " ((3, 'Fog , Rain'), 177),\n",
       " ((1, 'Fog'), 164),\n",
       " ((0, 'Rain , Snow'), 161),\n",
       " ((4, 'Fog , Rain'), 177),\n",
       " ((0, 'Fog , Rain'), 170),\n",
       " ((2, 'Snow'), 190),\n",
       " ((5, 'Fog , Snow'), 93),\n",
       " ((6, 'Fog'), 82),\n",
       " ((4, 'Fog , Snow'), 178),\n",
       " ((6, 'Snow'), 85),\n",
       " ((1, 'Fog , Rain'), 183),\n",
       " ((2, 'Rain , Snow'), 186),\n",
       " ((3, 'Snow'), 188),\n",
       " ((6, 'Rain , Snow'), 90),\n",
       " ((1, 'Fog , Rain , Snow'), 187),\n",
       " ((2, 'Fog , Snow'), 135),\n",
       " ((6, 'Fog , Rain'), 76),\n",
       " ((4, 'Fog , Rain , Snow'), 179),\n",
       " ((0, 'Rain'), 170),\n",
       " ((2, 'Fog , Rain'), 177),\n",
       " ((3, 'Fog'), 185),\n",
       " ((5, 'Rain , Snow'), 109),\n",
       " ((0, 'Fog , Rain , Snow'), 156),\n",
       " ((5, 'Fog , Rain'), 93),\n",
       " ((3, 'Rain'), 181),\n",
       " ((1, 'Rain , Snow'), 181),\n",
       " ((0, 'Fog'), 178),\n",
       " ((2, 'Fog , Rain , Snow'), 156),\n",
       " ((2, 'Rain'), 184),\n",
       " ((1, 'Snow'), 194),\n",
       " ((5, 'Rain'), 105),\n",
       " ((1, 'Clear Skies'), 183),\n",
       " ((6, 'Fog , Snow'), 81),\n",
       " ((6, 'Thunderstorm'), 75),\n",
       " ((4, 'Rain'), 178),\n",
       " ((5, 'Clear Skies'), 108),\n",
       " ((1, 'Rain'), 183),\n",
       " ((4, 'Clear Skies'), 181)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mapper3(index,data):\n",
    "    # skip header row\n",
    "    if index==0:\n",
    "        data.next()\n",
    "    import csv\n",
    "    import datetime\n",
    "    reader = csv.reader(data)\n",
    "    for row in reader:\n",
    "        date = datetime.datetime.strptime(row[1], '%m/%d/%Y').weekday()\n",
    "        event = row[4]\n",
    "        numPeople = row[5].split('.')[0]\n",
    "        if event == 'Normal':\n",
    "            yield ((date, 'Clear Skies'), int(numPeople))\n",
    "        else:\n",
    "            yield ((date,event), int(numPeople))\n",
    "            \n",
    "def mapper4(index,data):\n",
    "    # skip header row\n",
    "    if index==0:\n",
    "        data.next()\n",
    "    import csv\n",
    "    import datetime\n",
    "    reader = csv.reader(data)\n",
    "    for row in reader:\n",
    "        date = datetime.datetime.strptime(row[1], '%m/%d/%Y').weekday()\n",
    "        event = row[4]\n",
    "        if event == 'Normal':\n",
    "            yield ((date, 'Clear Skies'), 1)\n",
    "        else:\n",
    "            yield ((date, event), 1)\n",
    "\n",
    "import operator\n",
    "mtaData = sc.textFile('dataset/clean-mta-data/clean-mta-data.csv',use_unicode=False).cache()\n",
    "\n",
    "# get the amount of people using the mta on each day of the week for different weathers\n",
    "# returns ((weekday, event), summation_of_passengers)\n",
    "rdd4 = mtaData.mapPartitionsWithIndex(mapper3)  \\\n",
    "                .reduceByKey(lambda x,y: x+y)\n",
    "\n",
    "# get the number of days by each day of the week (hour) for different weathers\n",
    "# returns ((weekday, event), summation_of_day_hour)\n",
    "rdd5 = mtaData.mapPartitionsWithIndex(mapper4) \\\n",
    "                .reduceByKey(lambda x,y: x+y) \\\n",
    "    \n",
    "rdd6 = rdd4.join(rdd5) \\\n",
    "           .map(lambda (e, (s, c)): (e, s/c)) \\\n",
    "           .collect()\n",
    "rdd6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [python2]",
   "language": "python",
   "name": "Python [python2]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
