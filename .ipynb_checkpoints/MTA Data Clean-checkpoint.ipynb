{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean data and prepare data for project #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import urllib2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['http://web.mta.info/developers/data/nyct/turnstile/turnstile_160102.txt', 'http://web.mta.info/developers/data/nyct/turnstile/turnstile_160109.txt', 'http://web.mta.info/developers/data/nyct/turnstile/turnstile_160116.txt', 'http://web.mta.info/developers/data/nyct/turnstile/turnstile_160123.txt', 'http://web.mta.info/developers/data/nyct/turnstile/turnstile_160130.txt']\n",
      "['http://web.mta.info/developers/data/nyct/turnstile/turnstile_160305.txt', 'http://web.mta.info/developers/data/nyct/turnstile/turnstile_160312.txt', 'http://web.mta.info/developers/data/nyct/turnstile/turnstile_160319.txt', 'http://web.mta.info/developers/data/nyct/turnstile/turnstile_160326.txt', 'http://web.mta.info/developers/data/nyct/turnstile/turnstile_160402.txt']\n",
      "['http://web.mta.info/developers/data/nyct/turnstile/turnstile_160604.txt', 'http://web.mta.info/developers/data/nyct/turnstile/turnstile_160611.txt', 'http://web.mta.info/developers/data/nyct/turnstile/turnstile_160618.txt', 'http://web.mta.info/developers/data/nyct/turnstile/turnstile_160625.txt', 'http://web.mta.info/developers/data/nyct/turnstile/turnstile_160702.txt']\n",
      "['http://web.mta.info/developers/data/nyct/turnstile/turnstile_160903.txt', 'http://web.mta.info/developers/data/nyct/turnstile/turnstile_160910.txt', 'http://web.mta.info/developers/data/nyct/turnstile/turnstile_160917.txt', 'http://web.mta.info/developers/data/nyct/turnstile/turnstile_160924.txt', 'http://web.mta.info/developers/data/nyct/turnstile/turnstile_161001.txt']\n",
      "['http://web.mta.info/developers/data/nyct/turnstile/turnstile_160102.txt', 'http://web.mta.info/developers/data/nyct/turnstile/turnstile_160109.txt', 'http://web.mta.info/developers/data/nyct/turnstile/turnstile_160116.txt', 'http://web.mta.info/developers/data/nyct/turnstile/turnstile_160123.txt', 'http://web.mta.info/developers/data/nyct/turnstile/turnstile_160130.txt']\n"
     ]
    }
   ],
   "source": [
    "#get files address for 2016 from MTA\n",
    "\n",
    "files_array = [] # total files\n",
    "spring_files = [] \n",
    "summer_files = []\n",
    "fall_files = []\n",
    "winter_files = []\n",
    "\n",
    "# get files address and sort by season\n",
    "def sort_by_season(t,addr):\n",
    "    month = str(t.strftime(\"%m\"))\n",
    "    if month[0] == '0':\n",
    "        month = month[1]\n",
    "        \n",
    "    if month == '3' or month == '4' or month == '5':\n",
    "        spring_files.append(addr)\n",
    "    elif month == '6' or month == '7' or month == '8':\n",
    "        summer_files.append(addr)\n",
    "    elif month == '9' or month == '10' or month == '11':\n",
    "        fall_files.append(addr)\n",
    "    else:\n",
    "        winter_files.append(addr)\n",
    "\n",
    "start_date = datetime.date(2016,1,2)\n",
    "end_date = datetime.date(2016,12,31)\n",
    "url = \"http://web.mta.info/developers/data/nyct/turnstile/turnstile_\"\n",
    "while (start_date <= end_date):\n",
    "    address = url + str(start_date.strftime(\"%y%m%d\"))+\".txt\"\n",
    "    files_array.append(address)\n",
    "    sort_by_season(start_date,address) \n",
    "    start_date += datetime.timedelta(days=7)\n",
    "    \n",
    "print files_array[:5]\n",
    "print spring_files[:5]\n",
    "print summer_files[:5]\n",
    "print fall_files[:5]\n",
    "print winter_files[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('A002', 'R051', '02-00-00', '59 ST', 'NQR456', 'BMT', '12/26/2015', '03:00:00', 'REGULAR', '0005469540', '000184663'), ('A002', 'R051', '02-00-00', '59 ST', 'NQR456', 'BMT', '12/26/2015', '07:00:00', 'REGULAR', '0005469543', '000184664'), ('A002', 'R051', '02-00-00', '59 ST', 'NQR456', 'BMT', '12/26/2015', '11:00:00', 'REGULAR', '0005469617', '000184673'), ('A002', 'R051', '02-00-00', '59 ST', 'NQR456', 'BMT', '12/26/2015', '15:00:00', 'REGULAR', '0005469821', '000184680'), ('A002', 'R051', '02-00-00', '59 ST', 'NQR456', 'BMT', '12/26/2015', '19:00:00', 'REGULAR', '0005470180', '000184687'), ('A002', 'R051', '02-00-00', '59 ST', 'NQR456', 'BMT', '12/26/2015', '23:00:00', 'REGULAR', '0005470411', '000184690'), ('A002', 'R051', '02-00-00', '59 ST', 'NQR456', 'BMT', '12/27/2015', '03:00:00', 'REGULAR', '0005470459', '000184692'), ('A002', 'R051', '02-00-00', '59 ST', 'NQR456', 'BMT', '12/27/2015', '07:00:00', 'REGULAR', '0005470479', '000184693'), ('A002', 'R051', '02-00-00', '59 ST', 'NQR456', 'BMT', '12/27/2015', '11:00:00', 'REGULAR', '0005470529', '000184699'), ('A002', 'R051', '02-00-00', '59 ST', 'NQR456', 'BMT', '12/27/2015', '15:00:00', 'REGULAR', '0005470679', '000184700')]\n"
     ]
    }
   ],
   "source": [
    "my_array = []\n",
    "# my_array.append(['C/A', 'UNIT', 'SCP', 'STATION', 'LINENAME', \n",
    "#                  'DIVISION', 'DATE', 'TIME', 'DESC', 'ENTRIES', 'EXITS'])\n",
    "\n",
    "# convert json to array\n",
    "def convert_to_array(data,arr):\n",
    "    my_line = data\n",
    "    my_line = my_line.split(',')\n",
    "    my_line_10 = my_line[10][:9]\n",
    "    my_line.remove(my_line[10])\n",
    "    my_line.append(my_line_10)\n",
    "    my_line = tuple(my_line)\n",
    "    arr.append(my_line)\n",
    "    \n",
    "# get data from url\n",
    "def get_data_input_url(input_file,arr):\n",
    "    data = urllib2.urlopen(input_file)\n",
    "    iter_data = iter(data)\n",
    "    next(iter_data)\n",
    "    for i in data:\n",
    "        convert_to_array(i,arr)\n",
    "        \n",
    "#use for loop to get all the data\n",
    "get_data_input_url(files_array[0],my_array)\n",
    "\n",
    "print(my_array[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mapper1(row):\n",
    "    return (row[3])\n",
    "\n",
    "def reducer1(counts, pair):\n",
    "    counts[pair] = counts.get(pair, 0)+1\n",
    "    return counts\n",
    "\n",
    "#get popular station, this function will take time to run.\n",
    "def get_popular_station(m_file,m_arr):\n",
    "    for i in xrange(0,len(m_file)):\n",
    "        get_data_input_url(m_file[i],m_arr)\n",
    "    \n",
    "    output1 = reduce(reducer1, map(mapper1, m_arr), {}).items()\n",
    "    output1.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    print output1[:10]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('34 ST-PENN STA', 56078), ('FULTON ST', 53376), ('23 ST', 39243), ('GRD CNTRL-42 ST', 34467), ('CANAL ST', 32294), ('34 ST-HERALD SQ', 30896), ('CHAMBERS ST', 29720), ('86 ST', 28630), ('59 ST', 28246), ('42 ST-PORT AUTH', 28124)]\n"
     ]
    }
   ],
   "source": [
    "#popular station for spring 2016\n",
    "spring_array = []\n",
    "get_popular_station(spring_files,spring_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('34 ST-PENN STA', 53828), ('FULTON ST', 52781), ('23 ST', 38995), ('GRD CNTRL-42 ST', 34113), ('CANAL ST', 32316), ('34 ST-HERALD SQ', 29982), ('CHAMBERS ST', 29691), ('59 ST', 28889), ('42 ST-PORT AUTH', 28483), ('86 ST', 28479)]\n"
     ]
    }
   ],
   "source": [
    "#popular station for summer 2016\n",
    "summer_array = []\n",
    "get_popular_station(summer_files,summer_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('34 ST-PENN STA', 54115), ('FULTON ST', 52783), ('23 ST', 39005), ('GRD CNTRL-42 ST', 34184), ('CANAL ST', 31981), ('34 ST-HERALD SQ', 30093), ('CHAMBERS ST', 29743), ('59 ST', 29251), ('86 ST', 28651), ('42 ST-PORT AUTH', 28145)]\n"
     ]
    }
   ],
   "source": [
    "#popular station for fall 2016\n",
    "fall_array = []\n",
    "get_popular_station(fall_files,fall_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('34 ST-PENN STA', 59561), ('FULTON ST', 57155), ('23 ST', 42211), ('GRD CNTRL-42 ST', 36611), ('CANAL ST', 35037), ('34 ST-HERALD SQ', 33049), ('CHAMBERS ST', 32367), ('59 ST', 31134), ('86 ST', 31079), ('42 ST-PORT AUTH', 31037)]\n"
     ]
    }
   ],
   "source": [
    "#popular station for winter 2016\n",
    "winter_array = []\n",
    "get_popular_station(winter_files,winter_array)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [python2]",
   "language": "python",
   "name": "Python [python2]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
